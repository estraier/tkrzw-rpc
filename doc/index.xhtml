<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta charset="UTF-8"/>
<title>Tkrzw-RPC: RPC interface of Tkrzw</title>
<link href="prism.css" rel="stylesheet"/>
<link href="tk-icon.png" rel="icon" type="image/png" sizes="144x144"/>
<style>/*<![CDATA[*/
html,body,article,p,pre,code,li,dt,dd,td,th,div { font-size: 12pt; }
html { margin: 0; padding: 0; background: #eeeeee; }
body { width: 100%; margin: 0; padding: 0; background: #eeeeee; text-align: center; }
body { animation: fadeIn 0.8s ease 0s 1 normal; -webkit-animation: fadeIn 0.8s ease 0s 1 normal; }
article { display: inline-block; max-width: 100ex; overflow: hidden; border: 1px solid #aaaaaa; border-radius: 2ex;
  margin: 2ex 1ex; padding: 3ex 3ex; background: #ffffff; text-align: left; line-height: 1.6; color: #111111; }
h1,h2,h3,h4,h5,h6 { color: #000000; margin: 2ex 0 0 0; text-indent: 0; }
h1 { text-align: center; margin: 2ex 0 3ex 0; }
p { text-indent: 2ex; }
pre { margin-left: 1.5ex; padding: 0.4ex 0.6ex; border: solid 1px #dddddd; border-radius: 0.5ex;
  white-space: pre-wrap; word-wrap: break-word; line-height: 1.2; text-indent: 0; font-size: 10pt; }
code { font-weight: bold; }
pre[class*="language-"] { font-size: 10pt; line-height: 120%; padding: 0.5ex 0.8ex; background: #f8f8f8;
  max-height: 70ex; }
pre.rawtext { font-size: 9pt; line-height: 110%; padding: 0.5ex 0.8ex; background: #f8f8f8; }
li { margin-left: 0.2ex; }
dt { margin-left: 2.0ex; }
dd { margin-left: 5.0ex; }
table { margin-left: 1.5ex; border-collapse: collapse; }
td,th { padding: 0 0.5ex; border: 1px solid #dddddd; }
td { font-size: 11pt; }
td.num { text-align: right; }
th { font-size: 10pt; font-weight: normal; background: #eeeeee; }
a { color: #004488; }
div.logo { text-align: center; }
div.logo img { max-width: 30ex; }
div.illustration { text-align: center; }
div.illustration img { max-width: 70ex; }
div.chart { text-align: left; }
div.chart img { max-width: 80ex; }
h2 a.headanc, h3 a.headanc {
  display: none;
  font-size: 8pt;
  vertical-align: super;
  padding-left: 0.5ex;
}
h2:hover a.headanc, h3:hover a.headanc {
  display: inline;
  font-size: 10pt;
  vertical-align: super;
}
#toc_div { zoom: 85%; }
.toc_line_h2 { margin-left: 2ex; }
.toc_line_h3 { margin-left: 5ex; }
/*]]>*/</style>
<script type="text/javascript">/*<![CDATA[*/
function insert_toc() {
  let first_head = document.querySelector("h2, h3");
  let toc_div = document.createElement('div');
  toc_div.id = "toc_div";
  let toc_head = document.createElement('h2');
  toc_head.textContent = "Table of Contents";
  toc_head.id = "toc";
  toc_div.appendChild(toc_head);
  first_head.parentNode.insertBefore(toc_div, first_head);
  for (let header of document.querySelectorAll("h2, h3")) {
    if (header != toc_head) {
      let toc_line = document.createElement('div');
      toc_line.className = "toc_line_" + header.tagName;
      let toc_anchor = document.createElement('a');
      toc_anchor.href = "#" + header.id;
      toc_anchor.textContent = header.textContent
      toc_line.appendChild(toc_anchor);
      toc_div.appendChild(toc_line);
    }
    let anchor = document.createElement('a');
    anchor.textContent = "#"
    anchor.href = "#" + header.id;
    anchor.className = "headanc";
    header.appendChild(anchor);
  }
}
window.onload = function(){
  insert_toc();
}
/*]]>*/</script>
</head>
<body>
<script src="prism.js"/>
<article>

<h1 id="title">Tkrzw-RPC: RPC interface of Tkrzw</h1>

<h2 id="overview">Overview</h2>

<p>Tkrzw-RPC is a package of a server program which manages databases of Tkrzw and a library to access the service via gRPC protocol.  Tkrzw is a library to manage key-value storages in various algorithms.  With Tkrzw, applications can handle database files efficiently in the process without any network overhead.  However, multiple processes cannot open the same database file simultaneously.  Tkrzw-RPC solves this issue by using a server program which manages database files and allowing other processes to access the contents via RPC.</p>

<div id="networdstructure" class="illustration"><img src="network.svg"/></div>

<p>One server process can handle multiple databases, each of which can be different data structure and tuning parameters.  Each database is an instance of the <a href="https://dbmx.net/tkrzw/#polydbm_overview">PolyDBM</a> class, which is an adapter class to handle the following classes with the same interface.</p>

<ul>
<li><strong><a href="https://dbmx.net/tkrzw/#hashdbm_overview">HashDBM</a></strong> : File database manager implementation based on hash table.</li>
<li><strong><a href="https://dbmx.net/tkrzw/#treedbm_overview">TreeDBM</a></strong> : File database manager implementation based on B+ tree.</li>
<li><strong><a href="https://dbmx.net/tkrzw/#skipdbm_overview">SkipDBM</a></strong> : File database manager implementation based on skip list.</li>
<li><strong><a href="https://dbmx.net/tkrzw/#tinydbm_overview">TinyDBM</a></strong> : On-memory database manager implementation based on hash table.</li>
<li><strong><a href="https://dbmx.net/tkrzw/#babydbm_overview">BabyDBM</a></strong> : On-memory database manager implementation based on B+ tree.</li>
<li><strong><a href="https://dbmx.net/tkrzw/#cachedbm_overview">CacheDBM</a></strong> : On-memory database manager implementation with LRU deletion.</li>
</ul>

<p>The library of Tkrzw-RPC is a C++ library to access the database service via gRPC protocol.  Thus, you can easily write application programs in C++.  You use the class <a href="#remotedbm_overview">RemoteDBM</a> whose API is very similar to the PolyDBM class so that you can use it as if you operates local databases.  Moreover, gRPC automates to generate client interfaces in various languages, based on the service definition in the protocol buffers <a href="https://github.com/estraier/tkrzw-rpc/blob/master/tkrzw_rpc.proto">tkrzw_rpc.proto</a>.  Tkrzw-RPC also provides command line utilities to access the database service.</p>

<p>The server supports asynchronous replication for high availability of the service.  Every update on the databases of a server called "master" can be monitored by another server called "slave" and updates are applied to the databases on the slave immediately.  Thus, databases on both servers are synchronized.  If the master dies, clients connects to the slave to continue the service without any downtime.  The slave is treated as the new master by adding another slave.  Slaves can be used as read-only replicas for load distribution.  The "dual masters" topology is also available, where two servers replicate each other.</p>

<h2 id="download">Download</h2>

<p>You can download source packages in the following directories.</p>

<ul>
<li><a href="http://dbmx.net/tkrzw-rpc/pkg/">C++ source packages</a></li>
</ul>

<h2 id="api_documents">API Documents</h2>

<p>The following are API documents for each language.</p>

<ul>
<li><a href="http://dbmx.net/tkrzw-rpc/api/">C++ API documents</a></li>
</ul>

<h2 id="installation">Installation</h2>

<p>Tkrzw-RPC is implemented based on the C++17 standard and POSIX API.  It works on Unix-like systems (Linux, FreeBSD, and Mac OS X), and GCC (version 7.3 or later) is required to build programs.</p>

<p>Download the latest version of the source packages.  The core library of <a href="https://grpc.io/">gRPC</a> is also required so install it beforehand.</p>

<p>To build the server and the library, usually, you will run the following commands.  If you have installed Tkrzw and gRPC into another location than "/usr/local", specify the prefix by the "--with-extra" of "./configure", such as "--with-extra=/opt/homebrew".</p>

<pre><code class="language-shell-session"><![CDATA[$ ./configure --enable-opt-native
$ make
$ sudo make install
]]></code></pre>

<p>By default, the library and related files are installed under "/usr/local".  If you want to install the files under "/usr", specify "--prefix=/usr" with the configure scriptt.</p>

<pre><code class="language-shell-session"><![CDATA[/usr/local/lib/libtkrzw.a
/usr/local/lib/libtkrzw.so
/usr/local/lib/libtkrzw_rpc.a
/usr/local/include/tkrzw_dbm_remote.h
/usr/local/share/tkrzw/tkrzw_rpc.proto
/usr/local/bin/tkrzw_rpc_build_util
/usr/local/bin/tkrzw_server
/usr/local/bin/tkrzw_dbm_remote_util
/usr/local/bin/tkrzw_dbm_remote_perf
]]></code></pre>

<p>To run the test suite, GoogleTest is required.  Although testing the library is not necessary for most users, you can do so just in case.</p>

<pre><code class="language-shell-session"><![CDATA[$ make test
$ make testrun
]]></code></pre>

<p>You can run end-to-end tests with the following procedures.  First, run the server.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --log_level debug
]]></code></pre>

<p>While the server is running, run the client commands on another terminal.</p>

<pre><code class="language-shell-session"><![CDATA[$ make check
]]></code></pre>

<p>If the message "Checking completed" is shown, all checks are OK.  You can stop the server process by inputting Ctrl-C on the same terminal.</p>

<h2 id="Kickstart">Kickstart</h2>

<p>Let's run the server with a simple setting.  By default, an on-memory database of TinyDBM is specified.  By specifying the log level to "debug", every RPC call to the service is printed in the log stream.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --log_level debug
]]></code></pre>

<p>Let's play with the command line utilities on another terminal.</p>

<pre><code class="language-shell-session"><![CDATA[# Stores three records
$ tkrzw_dbm_remote_util set one first
$ tkrzw_dbm_remote_util set two second
$ tkrzw_dbm_remote_util set three third

# Retrieves each record
$ tkrzw_dbm_remote_util get one
first
$ tkrzw_dbm_remote_util get two
second
$ tkrzw_dbm_remote_util get three
third

# Removes one record
$ tkrzw_dbm_remote_util remove one

# Lists all records
$ tkrzw_dbm_remote_util list
three    third
two      second
]]></code></pre>

<p>Stop the server by inputting Ctrl-C on the terminal of the server command.  Such logs as the following are printed.</p>

<pre class="rawtext"><![CDATA[2021/09/05 12:16:45 [INFO] ======== Starting the process 39438 as a command ========
2021/09/05 12:16:45 [INFO] Version: rpc_pkg=0.7.2, rpc_lib=1.5.0, core_pkg=1.0.7, core_lib=1.50.0
2021/09/05 12:16:45 [INFO] Opening a database: #dbm=tiny
2021/09/05 12:16:45 [INFO] Building the sync server: address=0.0.0.0:1978
2021/09/05 12:16:57 [DEBUG] [::1]:32788 [Set] key: "one" value: "first" overwrite: true
2021/09/05 12:17:01 [DEBUG] [::1]:32792 [Set] key: "two" value: "second" overwrite: true
2021/09/05 12:17:05 [DEBUG] [::1]:32794 [Set] key: "three" value: "third" overwrite: true
2021/09/05 12:17:12 [DEBUG] [::1]:32796 [Get] key: "one"
2021/09/05 12:17:15 [DEBUG] [::1]:32798 [Get] key: "two"
2021/09/05 12:17:17 [DEBUG] [::1]:32800 [Get] key: "three"
2021/09/05 12:17:56 [DEBUG] [::1]:32804 [Remove] key: "list"
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_FIRST
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_GET
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_NEXT
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_GET
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_NEXT
2021/09/05 12:18:00 [DEBUG] [::1]:32806 [Iterate] operation: OP_GET
2021/09/05 12:18:03 [INFO] Shutting down by signal: 2
2021/09/05 12:18:03 [INFO] The server finished
2021/09/05 12:18:03 [INFO] Closing a database
2021/09/05 12:18:03 [INFO] ======== Ending the process 39438 in success ========
]]></pre>

<p>As the on-memory database was not associated with any file, records in the database vanished when the server shut down.  Next, let's run the server with two on-memory databases associated with files.  The first database is TinyDBM, which is on-memory hash database.  The second database is BabyDBM, which is on-memory tree database.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --log_level debug "casket-1.tkmt" "casket-2.tkmb"
]]></code></pre>

<p>Let's add serveral records to each databases.  The target of the operation is specified by the "--index" option, whose default value is zero referring to the first database.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util set one first
$ tkrzw_dbm_remote_util set two second
$ tkrzw_dbm_remote_util set three third

$ tkrzw_dbm_remote_util set --index 1 japan tokyo
$ tkrzw_dbm_remote_util set --index 1 china beijing
$ tkrzw_dbm_remote_util set --index 1 korea seoul
]]></code></pre>

<p>Stop the server by inputting Ctrl-C on the terminal of the server command.  This time, all records are stored in the specified files.  Then, restart the server with the same arguemnts.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --log_level debug "casket-1.tkmt" "casket-2.tkmb"
]]></code></pre>

<p>Confirm that the records are loaded properly.  As the second database is an ordered database, the record keys are in acsending order for sure.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util list
three	 third
two	   second
one	   first

$ tkrzw_dbm_remote_util list --index 1
china  beijing
japan  tokyo
korea  seoul
]]></code></pre>

<p>Read <a href="https://dbmx.net/tkrzw/api-rpc/">the C++ API documents</a> for usage of the C++ client library.  Then, let's build a sample program.  Make a file of the following C++ code and save it as "helloworld.cc".</p>

<pre><code class="language-shell-session"><![CDATA[#include "tkrzw_dbm_remote.h"

int main(int argc, char** argv) {
  tkrzw::RemoteDBM dbm;
  dbm.Connect("localhost", 1978).OrDie();
  dbm.Set("hello", "world").OrDie();
  std::cout << dbm.GetSimple("hello") << std::endl;
  dbm.Disconnect().OrDie();
  return 0;
}
]]></code></pre>

<p>To build an application program, you'll typically run a command like this.  The compiler flag "-std=c++17" is necessary if the default C++ version of your compiler is older than C++17.</p>

<pre><code class="language-shell-session"><![CDATA[$ g++ -std=c++17 -pthread -I/usr/local/include \
  -O2 -Wall helloworld.cc -o helloworld \
  -L/usr/local/lib -ltkrzw_rpc -lgrpc++_reflection -lgrpc++ -lgrpc -lgpr -lprotobuf \
  -ltkrzw -lstdc++ -lpthread
]]></code></pre>

<p>The bundled command "tkrzw_rpc_build_util" is useful to know necessary CPPFLAGS (flags for the preprocessor), and LDFLAGS (flags for the linker).</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_rpc_build_util config -i
-I/usr/local/include
$ tkrzw_rpc_build_util config -l
-L/usr/local/lib -ltkrzw_rpc -lgrpc++_reflection -lgrpc++ -lgrpc -lgpr -lprotobuf -ltkrzw -lstdc++ -lpthread -lm -lc
]]></code></pre>

<p>In some environments, you can also use the "pkg-config" command to list up those flags.</p>

<pre><code class="language-shell-session"><![CDATA[$ export PKG_CONFIG_PATH="/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH"
$ pkg-config --cflags-only-I tkrzw-rpc
-I/usr/local/include
$ pkg-config --libs tkrzw-rpc
-L/usr/local/lib -ltkrzw_rpc -lgrpc++_reflection -lgrpc++ -lgrpc -lgpr -lprotobuf -ltkrzw -lstdc++ -lpthread -lm -lc
]]></code></pre>

<p>Build the above sample program and run it while the server is running.</p>

<pre><code class="language-shell-session"><![CDATA[$ ./helloworld
world
]]></code></pre>

<h2 id="commands">Commands Line Interfaces</h2>

<h3 id="commands_tkrzw_rpc_build_util">tkrzw_rpc_build_util: Build Utilities</h3>

<p>tkrzw_rpc_build_util is a command for build utilities.  Thereby, you can obtain flags to build your own program using the library of Tkrzw-RPC.  The usage is the following.  A subcommand name comes as the first argument.  Some options and other arguments can follow.</p>

<dl>
<dt><code>tkrzw_rpc_build_util config [<var>options</var>]</code></dt>
<dd>Prints configurations.</dd>
<dt><code>tkrzw_rpc_build_util version</code></dt>
<dd>Prints the version information.</dd>
</dl>

<dl>
<dt>Options of the config subcommand:</dt>
<dd><code>-v</code> : Prints the version number.</dd>
<dd><code>-i</code> : Prints C++ preprocessor options for build.</dd>
<dd><code>-l</code> : Prints linker options for build.</dd>
<dd><code>-p</code> : Prints the prefix for installation.</dd>
</dl>

<p>The following is a way to build your own application without setting complicated flags.</p>

<pre><code class="language-shell-session"><![CDATA[$ g++ -std=c++17 -pthread \
  $(tkrzw_rpc_build_util config -i) \
  -O2 -Wall helloworld.cc -o helloworld \
  $(tkrzw_rpc_build_util config -l)
]]></code></pre>

<h3 id="commands_tkrzw_server">tkrzw_server: Database Server</h3>

<p>tkrzw_server is a command to run the database service of Tkrzw-RPC.  One server process can handle multiple databases at the same time.  The process can be a daemon process to run in the background.  The server can use either of IPv4, IPv6, or UNIX domain socket as the network interface.</p>

<dl>
<dt><code>tkrzw_server [<var>options</var>] [<var>db_configs</var>]</code></dt>
<dd>Runs the database service.</dd>
</dl>

<dl>
<dt>Options:</dt>
<dd><code>--version</code> : Prints the version number and exit.</dd>
<dd><code>--address <var>str</var></code> : The address/hostname and the port of the server (default: 0.0.0.0:1978)</dd>
<dd><code>--async</code> : Uses the asynchronous API on ths server.</dd>
<dd><code>--threads <var>num</var></code> : The maximum number of worker threads. (default: 1)</dd>
<dd><code>--log_file <var>str</var></code> : The file path of the log file. (default: /dev/stdout)</dd>
<dd><code>--log_level <var>str</var></code> : The minimum log level to be stored: debug, info, warn, error, fatal. (default: info)</dd>
<dd><code>--log_date <var>str</var></code> : The log date format: simple, simple_micro, w3cdtf, w3cdtf_micro, rfc1123, epoch, epoch_micro. (default: simple)</dd>
<dd><code>--log_td <var>num</var></code> : The log time difference in seconds. (default: 99999=local)</dd>
<dd><code>--server_id <var>num</var></code> : The server ID. (default: 1)</dd>
<dd><code>--ulog_prefix <var>str</var></code> : The prefix of the update log files.</dd>
<dd><code>--ulog_max_file_size <var>num</var></code> : The maximum file size of each update log file. (default: 1Gi)</dd>
<dd><code>--repl_ts_file <var>str</var></code> : The replication timestamp file.</dd>
<dd><code>--repl_ts_from_dbm</code> : Uses the database timestamp if the timestamp file doesn't exist.</dd>
<dd><code>--repl_ts_skew <var>num</var></code> : Skews the timestamp by a value.</dd>
<dd><code>--repl_wait <var>num</var></code> : The time in seconds to wait for the next log. (default: 1)</dd>
<dd><code>--pid_file <var>str</var></code> : The file path of the store the process ID.</dd>
<dd><code>--daemon</code> : Runs the process as a daemon process.</dd>
<dd><code>--shutdown_wait <var>num</var></code> : Time in seconds to wait for the service shutdown gracefully.</dd>
<dd><code>--read_only</code> : Opens the databases in the read-only mode.</dd>
</dl>

<p>If you don't set database configurations, an on-memory database of TinyDBM with the default tuning is served.  You can set one or more database configurations too.  Each confituration is in the format of "path#name1=value1,name2=value2,..." which is composed of the file path of the database, "#", and CSV of tuning parameters.  The extension of the database path determines the database class.  ".tkh" for HashDBM, ".tkt" for TreeDBM, ".tks" for SkipDBM, ".tkmt" for TinyDBM, ".tkmb" for BabyDBM, and ".tkmc" for CacheDBM.  The database path can be empty for on-memory databases.  The "dbm" parameter overwrites the decision by the extension.  The following are samples.  See <a href="https://dbmx.net/tkrzw/#polydbm_overview">PolyDBM</a> for details.</p>

<dl>
<dt>#dbm=BabyDBM</dt>
<dd>Opens a BabyDBM without associating any file.</dd>
<dt>casket#dbm=HashDBM</dt>
<dd>Opens the file "casket" as a HashDBM.</dd>
<dt>casket.tkh#num_buckets=10M,update_mode=appending,restore_mode=sync</dt>
<dd>Opens the file "casket.tkh" as a HashDBM.  The bucket number is set to 10 million.  Uses the appending update mode and the synchronous restore mode.</dd>
<dt>casket.tkh#num_buckets=100M,align_pow=8,cache_buckets=1,file=pos-para,block_size=512,access_options=direct:padding:pagecache</dt>
<dd>Opens the file "casket.tkh" as a HashDBM.  The bucket number is set to 100 million.  The other parameters are tuned for direct I/O.</dd>
<dt>casket.tkt#num_buckets=1M,max_cached_pages=100K,record_comp_mode=lz4</dt>
<dd>Opens the file "casket.tkt" as a TreeDBM.  The bucket number is set to 1 million.  The maximum number of cached pages is 100 thousand.  Pages are compressed with LZ4.</dd>
<dt>casket.tks#sort_mem_size=2Gi,max_cached_records=100K</dt>
<dd>Opens the file "casket.tkt" as a TreeDBM.  The memory size for sorting is 2GiB.  The maximum number of cached records is 100 thousand.</dd>
<dt>casket.tkmt#num_buckets=10M</dt>
<dd>Opens the file "casket.tkmt" as a TinyDBM.  The bucket number is set to 10 million.</dd>
<dt>casket.tkmb</dt>
<dd>Opens the file "casket.tkmb" as a BabyDBM.</dd>
<dt>casket.tkmc#cap_rec_num=10M,cap_mem_size=2Gi</dt>
<dd>Opens the file "casket.tkmc" as a CacheDBM.  The maximum number of records is 10 million.  The total memory size to use is 2GiB.</dd>
</dl>

<p>By default, the server address is "0.0.0.0:1978", which means that the socket is bound to all network interfaces of IPv4 and IPv6 on the machine and that the port number is 1978.  To use a UNIX domain socket, specify the socket file path like "unix:/run/tkrzw_server.socket".</p>

<p>By default, the server uses the synchronous API of gRPC.  If the number of clients is limited (say, 20 or less) and they don't call RPC continuously, the maximum throughput of the server doesn't matter but the least latency does.  In such a case, using the synchronous API leads to the best performance.  Otherwise, you will pursue the maximum throughput of the server.  Then, you should specify the "--async" option to use the asynchronous API.  It enables the server to handle 10 thousands of connections at the same time and show more throughput than 100 thousand QPS.  The "--threads" option specifies the maximum number of worker threads used by the synchronous API, or it specifies the fixed number of queue-thread pairs used in the asynchronous API.  Usually, the number of threads should be the same as the number of cores of the CPU.  If you run clients on the same machine and they use much CPU time, the number of threads of the server should be less.</p>

<p>To finish the server process running on foreground, input Ctrl-C on the terminal.  If you run the server as a system service, run the process as a daemon with the "--daemon" option.  To finish the daemon process, send a termination signal such as SIGTERM by the "kill" command.  If a daemon process catches SIGHUP, the log file is re-opened.  To send signals to the process, you have to know the process ID.  So, it's a good practice to write the process ID to a file by the "--pid" flag.  Because thr current directory of a daemon process is changed to the root directory, paths of related files should be described as their absolute paths.</p>

<p>The following command starts the database service as a daemon process.  Usually, it is run by the start up script of the system.</p>

<pre><code class="language-shell-session"><![CDATA[tkrzw_server --address 0.0.0.0:1978 \
  --async --threads 4 \
  --log_file /var/log/tkrzw_server.log \
  --pid_file /run/tkrzw_server.pid \
  --daemon \
  "/var/db/casket.tkh#num_buckets=10M"
]]></code></pre>

<p>The following command stops the database service gracefully.  Usually, it is run by the the shutdown script of the system.</p>

<pre><code class="language-shell-session"><![CDATA[if test -f /run/tkrzw_server.pid
then
  kill -TERM `cat /run/tkrzw_server.pid`
fi
]]></code></pre>

<p>For log rotation, you run the following script.  Usually, it is run by a cron script invoked periodically.</p>

<pre><code class="language-shell-session"><![CDATA[mv /var/log/tkrzw_server.log /var/log/tkrzw_server.log.`date "+%Y%m%d%H%M%S"`
if test -f /run/tkrzw_server.pid
then
  kill -HUP `cat /run/tkrzw_server.pid`
fi
]]></code></pre>

<h3 id="commands_tkrzw_dbm_remote_util">tkrzw_dbm_remote_util: Database Client</h3>

<p>tkrzw_dbm_remote_util is a client command to invoke RPCs.  Thereby, you can set records, retrieve records, remove records, and rebuild databases.  A subcommand name comes as the first argument.  Some options and other arguments can follow.</p>

<dl>
<dt><code>tkrzw_dbm_remote_util echo [<var>options</var>] [<var>message</var>]</code></dt>
<dd>Invokes an echoing back test.</dd>
<dt><code>tkrzw_dbm_remote_util inspect [<var>options</var>] [<var>attr</var>]</code></dt>
<dd>Prints inspection of a database file.</dd>
<dt><code>tkrzw_dbm_remote_util get [<var>options</var>] <var>key</var></code></dt>
<dd>Gets a record and prints it.</dd>
<dt><code>tkrzw_dbm_remote_util set [<var>options</var>] <var>key</var> <var>value</var></code></dt>
<dd>Sets a record.</dd>
<dt><code>tkrzw_dbm_remote_util remove [<var>options</var>] <var>key</var></code></dt>
<dd>Removes a record.</dd>
<dt><code>tkrzw_dbm_remote_util list [<var>options</var>]</code></dt>
<dd>Lists up records and prints them.</dd>
<dt><code>tkrzw_dbm_remote_util clear [<var>options</var>]</code></dt>
<dd>Removes all records.</dd>
<dt><code>tkrzw_dbm_remote_util rebuild [<var>options</var>] [<var>params</var>]</code></dt>
<dd>Rebuilds a database file for optimization.</dd>
<dt><code>tkrzw_dbm_remote_util sync [<var>options</var>] [<var>params</var>]</code></dt>
<dd>Synchronizes a database file.</dd>
<dt><code>tkrzw_dbm_remote_util search [<var>options</var>] <var>pattern</var></code></dt>
<dd>Synchronizes a database file.</dd>
<dt><code>tkrzw_dbm_remote_util changemaster [<var>options</var>] [<var>master</var>]</code></dt>
<dd>Changes the master of replication.</dd>
<dt><code>tkrzw_dbm_remote_util replicate [<var>options</var>] [<var>db_configs</var>...]</code></dt>
<dd>Replicates updates to local databases.</dd>
</dl>

<dl>
<dt>Common options:</dt>
<dd><code>--version</code> : Prints the version number and exits.</dd>
<dd><code>--address</code> : The address and the port of the service (default: localhost:1978)</dd>
<dd><code>--timeout</code> : The timeout in seconds for connection and each operation.</dd>
<dd><code>--index</code> : The index of the DBM to access. (default: 0)</dd>
<dd><code>--multi</code> : Calls xxxMulti methods for get, set, and remove subcommands.</dd>
<dt>Options for the set subcommand:</dt>
<dd><code>--no_overwrite</code> : Fails if there's an existing record wit the same key.</dd>
<dd><code>--append <var>str</var></code> : Appends the value at the end after the given delimiter.</dd>
<dd><code>--incr <var>num</var></code> : Increments the value with the given initial value.</dd>
<dt>Options for the list subcommand:</dt>
<dd><code>--move <var>type</var></code> : Type of movement: first, jump, jumplower, jumplowerinc, jumpupper, jumpupperinc. (default: first)</dd>
<dd><code>--jump_key <var>str</var></code> : Specifies the jump key. (default: empty string)</dd>
<dd><code>--items <var>num</var></code> : The number of items to print. (default: 10)</dd>
<dd><code>--escape</code> : C-style escape is applied to the TSV data.</dd>
<dd><code>--keys</code> : Prints keys only.</dd>
<dt>Options for the sync subcommand:</dt>
<dd><code>--hard</code> : Does physical synchronization with the hardware.</dd>
<dt>Options for the search subcommand:</dt>
<dd><code>--mode <var>str</var></code> : The search mode: contain, begin, end, regex, edit, editbin, upper, upperinc, lower, lowerinc (default: contain)</dd>
<dd><code>--items <var>num</var></code> : The number of items to retrieve. (default: 10)</dd>
<dd><code>--escape</code> : C-style escape is applied to the TSV data.</dd>
<dd><code>--keys</code> : Prints keys only.</dd>
<dt>Options for the changemaster subcommand:</dt>
<dd><code>--ts_skew <var>num</var></code> : Skews the timestamp by a value.</dd>
<dt>Options for the replication subcommand:</dt>
<dd><code>--ts_file <var>str</var></code> : The replication timestamp file.</dd>
<dd><code>--ts_from_dbm</code> : Uses the database timestamp if the timestamp file doesn't exist.</dd>
<dd><code>--ts_skew <var>num</var></code> : Skews the timestamp by a value.</dd>
<dd><code>--server_id <var>num</var></code> : The server ID of the client.</dd>
<dd><code>--wait <var>num</var></code> : The time in seconds to wait for the next log.</dd>
<dd><code>--items <var>num</var></code> : The number of items to print. (default: 10)</dd>
<dd><code>--escape</code> : C-style escape is applied to the TSV data.</dd>
</dl>

<p>The following is a sample usage to make a remove database to associate country names to their capital cities' names.  If the extension of the file is "tkh", the type of the database is regarded as HashDBM.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util clear
$ tkrzw_dbm_remote_util set Japan Tokyo
$ tkrzw_dbm_remote_util set Korea Seoul
$ tkrzw_dbm_remote_util set China Beijing
$ tkrzw_dbm_remote_util get Japan
Tokyo
$ tkrzw_dbm_remote_util remove Japan
$ tkrzw_dbm_remote_util rebuild "num_buckets=100"
$ tkrzw_dbm_remote_util sync --hard
$ tkrzw_dbm_remote_util list
China  Beijing
Korea  Seoul
]]></code></pre>

<h3 id="commands_tkrzw_dbm_remote_perf">tkrzw_dbm_remote_perf: Performance Checker</h3>

<p>tkrzw_dbm_remote_perf is a command for checking performance of RPC invodation.  Thereby, you can check performance of remote database operations in various scenarios including multithreading.  A subcommand name comes as the first argument.  Some options and other arguments can follow.</p>

<dl>
<dt><code>tkrzw_dbm_remote_perf sequence [<var>options</var>]</code></dt>
<dd>Checks echoing/setting/getting/removing performance in sequence.</dd>
<dt><code>tkrzw_dbm_remote_perf wicked [<var>options</var>]</code></dt>
<dd>Checks consistency with various operations.</dd>
</dl>

<dl>
<dt>Common options:</dt>
<dd><code>--address</code> : The address and the port of the service (default: localhost:1978)</dd>
<dd><code>--timeout</code> : The timeout in seconds for connection and each operation.</dd>
<dd><code>--index</code> : The index of the DBM to access. (default: 0)</dd>
<dd><code>--iter <var>num</var></code> : The number of iterations. (default: 10000)</dd>
<dd><code>--size <var>num</var></code> : The size of each record value. (default: 8)</dd>
<dd><code>--threads <var>num</var></code> : The number of threads. (default: 1)</dd>
<dd><code>--separate</code> : Use separate instances for each thread.</dd>
<dd><code>--random_seed <var>num</var></code> : The random seed or negative for real RNG. (default: 0)</dd>
<dt>Options for the sequence subcommand:</dt>
<dd><code>--random_key</code> : Uses random keys rather than sequential ones.</dd>
<dd><code>--random_value</code> : Uses random length values rather than fixed ones.</dd>
<dd><code>--echo_only</code> : Does only echoing.</dd>
<dd><code>--set_only</code> : Does only setting.</dd>
<dd><code>--get_only</code> : Does only getting.</dd>
<dd><code>--iter_only</code> : Does only iterating.</dd>
<dd><code>--remove_only</code> : Does only removing.</dd>
<dd><code>--stream</code> : Uses the stream API.</dd>
<dd><code>--ignore_result</code> : Ignores the result status of streaming updates.</dd>
<dd><code>--multi <var>num</var></code> : Sets the size of a batch operation with xxxMulti methods.</dd>
<dt>Options for the wicked subcommand:</dt>
<dd><code>--iterator</code> : Uses iterators occasionally.</dd>
<dd><code>--clear</code> : Clears the database occasionally.</dd>
<dd><code>--rebuild</code> : Rebuilds the database occasionally.</dd>
</dl>

<p>The following is a sample usage to echo back 1 million messages, to store 1 million records of 8-byte keys and 8-byte values, to retrieve all of them, and to remove all of them in sequence.  The number of threads is 10 and each thread does 100 thousand operations.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_perf sequence --iter 100k --threads 10
]]></code></pre>

<h2 id="remotedbm_overview">RemoteDBM: Remote Database API</h2>

<p>The remote database is an interface to access the database service of Tkrzw-RPC.  It encapsulates the existence of the network layer so that you can use the features as if you operate local databases.  RemoteDBM is thread-safe so multiple threads can share the same instance, which saves the number of connections.  As the server supports both the synchronous API and the asynchronous API, RemoteDBM supports only the synchronous API on the client side.  Combination of the asynchronous API on the server side and the synchronous API on the client side is possible.  And, usually, it is the best setting because it maximizes the throughput of the server and simplifies the client code structure.</p>

<p>Before any operation, you have to call the Connect method to make a connection to the database server.  You set the server address and the port number, like "192.168.0.8:1978" and "example.com:8080".  To use a UNIX domain socket, set the path like "unix:/run/tkrzw_server.socket".  You can disconnect the connection by calling the Disconnect method.</p>

<p>The database service can handle multiple databases at the same time.  By default, the target database of operation by a RemoteDBM instance is the first database of the service.  If you access the second database, call the SetDBMIndex method with the parameter 1.  If you access the third database, set the parameter 2.  If multiple threads uses different indices, they should use separate instances of RemoteDBM.</p>

<p>To retrieve, store, and remove a record, you call the Get, Set, and Remove methods respectively.  If you handle multiple records at once, calling the GetMulti, SetMulti, and RemoveMulti methods is better in terms of performance.  CompareExchange, CompareExchangeMulti, and Increment are useful methods to do atomic operations.</p>

<p>The MakeStream method makes an instance of the Stream class.  A stream is bound to one thread on the server.  If you can call Get, Set, and Remove intensively, calling them via the stream gives you better performance.  The MakeIterator method makes an instance of the Iterator class.  An iterator is also bound to one thread on the server and it allows you stateful operations like First, Jump, Next, and Get.  Stream objects and iterator objects should be destructed as soon as possible, in order to release the server threads.</p>

<p>Most methods return a Status object to represent the result of the operation.  The meaning of the status code is the same as the local API except for the code NETWORK_ERROR which represents errors from gRPC.</p>

<h3 id="hashdbm_example">Example Code</h3>

<p>This is a code example where basic operations are done without checking errors.</p>

<pre><code class="language-cpp"><![CDATA[#include "tkrzw_dbm_remote.h"

// Main routine.
int main(int argc, char** argv) {
  // All symbols of Tkrzw are under the namespace "tkrzw".
  using namespace tkrzw;

  // Creates the database manager.
  RemoteDBM dbm;

  // Connects to the database service.
  dbm.Connect("localhost:1978");
  
  // Stores records.
  dbm.Set("foo", "hop");
  dbm.Set("bar", "step");
  dbm.Set("baz", "jump");

  // Retrieves records.
  std::cout << dbm.GetSimple("foo", "*") << std::endl;
  std::cout << dbm.GetSimple("bar", "*") << std::endl;
  std::cout << dbm.GetSimple("baz", "*") << std::endl;
  std::cout << dbm.GetSimple("outlier", "*") << std::endl;

  // Traverses records.
  std::unique_ptr<RemoteDBM::Iterator> iter = dbm.MakeIterator();
  iter->First();
  std::string key, value;
  while (iter->Get(&key, &value) == Status::SUCCESS) {
    std::cout << key << ":" << value << std::endl;
    iter->Next();
  }
  
  // Disconnects the connection.
  dbm.Disconnect();

  return 0;
}
]]></code></pre>

<p>This is a code example which represents a more serious use case with thorough error checks.</p>

<pre><code class="language-cpp"><![CDATA[#include "tkrzw_cmd_util.h"
#include "tkrzw_dbm_remote.h"

// Main routine.
int main(int argc, char** argv) {
  // All symbols of Tkrzw are under the namespace "tkrzw".
  using namespace tkrzw;

  // Creates the database manager.
  RemoteDBM dbm;

  // Connects to the database service.
  // The timeout is set to 1.5 seconds.
  Status status = dbm.Connect("localhost:1978", 1.5);
  if (status != Status::SUCCESS) {
    // Failure of the Connect operation is critical so we stop.
    Die("Connect failed: ", status);
  }

  // Makes a stream for better performance of intensive operations.
  std::unique_ptr<RemoteDBM::Stream> stream = dbm.MakeStream();

  // Stores records.
  // Bit-or assignment to the status updates the status if the original
  // state is SUCCESS and the new state is an error.
  status |= stream->Set("foo", "hop");
  status |= stream->Set("bar", "step");
  status |= stream->Set("baz", "jump");
  if (status != Status::SUCCESS) {
    // The Set operation shouldn't fail.  So we stop if it happens.
    Die("Set failed: ", status);
  }

  // Store records, ignoring the result status.
  stream->Set("quux", "land", true, true);
  stream->Set("xyzzy", "rest", true, true);

  // Retrieves records.
  // If there was no record, NOT_FOUND_ERROR would be returned.
  std::string value;
  status = stream->Get("foo", &value);
  if (status == Status::SUCCESS) {
    std::cout << value << std::endl;
  } else {
    std::cerr << "missing: " << status << std::endl;
  }

  // Destroys the stream if it is not used any longer.
  stream.reset(nullptr);

  // Makes an iterator for traversal operations.
  std::unique_ptr<RemoteDBM::Iterator> iter = dbm.MakeIterator();

  // Traverses records.
  if (iter->First() != Status::SUCCESS) {
    // Failure of the First operation is critical so we stop.
    Die("First failed: ", status);
  }
  while (true) {
    // Retrieves the current record data.
    std::string iter_key, iter_value;
    status = iter->Get(&iter_key, &iter_value);
    if (status == Status::SUCCESS) {
      std::cout << iter_key << ":" << iter_value << std::endl;
    } else {
      // This happens at the end of iteration.
      if (status != Status::NOT_FOUND_ERROR) {
        // Error types other than NOT_FOUND_ERROR are critical.
        Die("Iterator::Get failed: ", status);
      }
      break;
    }
    // Moves the iterator to the next record.
    status = iter->Next();
    if (status != Status::SUCCESS) {
      // This could happen if another thread removed the current record.
      if (status != Status::NOT_FOUND_ERROR) {
        // Error types other than NOT_FOUND_ERROR are critical.
        Die("Iterator::Get failed: ", status);
      }
      std::cerr << "missing: " << status << std::endl;
      break;
    }
  }

  // Destroys the iterator if it is not used any longer.
  iter.reset(nullptr);
  
  // Disconnects the connection.
  // Even if you forgot to disconnect it, the destructor would do it.
  // However, checking the status is a good manner.
  status = dbm.Disconnect();
  if (status != Status::SUCCESS) {
    // The Disconnect operation shouldn't fail.  So we stop if it happens.
    Die("Disconnect failed: ", status);
  }

  return 0;
}
]]></code></pre>

<h2 id="tips">Tips</h2>

<h3 id="tips_online_service">Typical Usage for Online Service</h3>

<p>HashDBM is designed to combine high performance and durability in the usage of online service.  Let's say, you run an online service and manage user data on a hash database.  The database is served by tkrzw_server and thousands of clients connect to the server and cause queries at 100K QPS at a peak time.  You run the server like this.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "0.0.0.0:1978" \
  --async --threads 8 \
  --log_file /var/log/tkrzw_server.log \
  --pid_file /run/tkrzw_server.pid \
  --daemon \
  "/var/db/casket.tkh#num_buckets=10M,update_mode=appending"
]]></code></pre>

<p>With the "--async" option, you use the asynchronous API of gRPC, which maximizes the throughput.  With the "--threads 8" option, the number of "completion queues" and the number of threads to consume tasks in each queue are set 8.  The value should be the same as the number of the CPU cores.</p>

<p>With "num_buckets=10M", the intial number of hash buckets is 10 million, which assumes the number of users is currently 10 million or less.  With "update_mode=appending", the update mode is in the appending mode, which realizes a high durability and a reasonable update performance on the large scale database.</p>

<p>As the update mode is the appending mode, the file size of the database grows by every update operations so you should rebuild the database periodically.  To do so, you set the follwing cron script which is invoked every midnight.</p>

<pre class="rawtext"><![CDATA[0 0 * * *    tkrzw_dbm_remote_util rebuild --address "localhost:1978" 2>&1 /dev/null
]]></pre>

<p>One of the most important features of HashDBM is that the Rebuild method is done without blocking other threads.  So, you can rebuild the database while serving it online.  The number of buckets is implicitly optimized for the current number of records.</p>

<h3 id="tips_measures_durability">Measures for Durability</h3>

<p>If the server process or the entire operating system crashes unexpectedly, the database file is marked "unhealthy".  If you start the server with an unhealthy database file, the file is restored automatically.  By default, the library makes the best effort to restore as many updates as possible.  How many updates are actually restored depends on the hehavior of the underlying file system, operating system and storage device.</p>

<p>If you want to guarantee that the past updates at a point are written all through the storage device, you should synchronize the database periodically or at an arbitrary critical point of operations.  If you invoke it every 10 minutes, you set the following cron script.</p>

<pre class="rawtext"><![CDATA[*/10 * * * *    tkrzw_dbm_remote_util sync --address "localhost:1978" --hard 2>&1 /dev/null
]]></pre>

<p>By setting the "--hard" option, synchronization is done to the storage device.  It means that the current state is restored even on system crashes by the kernel panic, power failures, or etc.  If you omit the option, synchronization is done to the file system, which is faster.  It guarantees the data restoration only against process crashes by segmentation faults, the OOM killer, etc.</p>

<p>If you want ACID traits of transactions, add "restore_mode=sync" to the database parameters so that the state at the time of the last synchronization is restored.  Client programs should call the Synchronize method after each transaction or at an arbitrary critical point of the business logic.  As performance and durability is in a relation of trade-off, how you call syncoronization should be determined depending on the usage and content.  See the <a href="https://dbmx.net/tkrzw/#tips_durability_settings">durability settings of Tkrzw</a> for details.</p>

<p>To make a backup file of a database while the server is running, you can use the "sync" subcommand and set the "make_backup" parameter whose value is empty.  A date suffix in GMT like ".backup.20210901233046" is added to the database file name to generage the backup file name.  If the value of "make_backup" is not empty, the value is used as the suffix.  For security, the available characters are "[-_.0-9a-zA-Z]".  The following cron setting makes a backup at 2:15 every night.</p>

<pre class="rawtext"><![CDATA[15 2 * * *    tkrzw_dbm_remote_util sync --address "localhost:1978" --hard "make_backup=" 2>&1 /dev/null
]]></pre>

<h3 id="tips_sharding">Sharding the Database</h3>

<p>Sharding is a technique to divide a database file into multiple files.  There are two major benefits.  One is that concurrency of multi-thread processing improves.  The other is that database-wide operations are divided so that blocking duration becomes shorter.  Moreover, the size of each temporary files becomes smaller.</p>

<p>Let's say, you shard a 1GB database into ten 102MB databases.  Synchronizing 1GB database would take 1 second during which all other operations are blocked.  In contrast, synchronizing one shard of 102MB file takes 0.1 seconds during which operations only on the shard are blocked.  Although the total time of synchronizing operation is the same, total blocking time of other threads is much less.  The same thing can be said to making backup files.  Moreover, the space efficiency of rebuilding the database also improves although rebuiling is not blocking.  Rebuilding a 1GB database requires a 1GB temporary file.  Meanwhile, rebuilding ten 102MB database requires one 102MB temporary file at the same time because the temporary file is removed after the operation for each shard.</p>

<p>The downside of sharding is that you compromise on ACID traits of transaction.  The CompareExchangeMulti operation is still atomic across threads and clients, it is not necessarily atomic across crashes.  That's because the system can crash in the middle of synchronizing each shard.  If you don't use CompareExchnageMulti or you can accpet the possibility of inconsistency on crashes, sharding is worth trying.</p>

<p>Let's set up a server of a file hash database in ten shards.  You just add the parameter "num_shards=10".  Note that the values of parameters for each shards should be divided by 10.  For example, 10 million hash buckets in total should be set with "num_buckets=1M".</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "0.0.0.0:1978" \
  --async --threads 8 \
  --log_file /var/log/tkrzw_server.log \
  --pid_file /run/tkrzw_server.pid \
  --daemon \
  "/var/db/casket.tkh#num_shards=10,num_buckets=1M,update_mode=appending"
]]></code></pre>

<p>As we have 10 shards, "casket.tkh-00000-of-00010", "casket.tkh-00001-of-00010", ..., "casket.tkh-00009-of-00010" are created.  If you make a backup, files like "casket.tkh.backup.20210908195557-00000-of-00010" et cetera are made.</p>

<p>External behaviors via RPC is the same whether the database is sharded or not.  Despite that sharding is done with a hash function, the iterator maintains the original order of the database if it is ordered one (TreeDBM, SkipDBM, BabyDBM).</p>

<p>You can shared on-memory databases too.  If an on-memory database is associated with a file, the blocking time during the Synchronize method might be an issue on online services.  Sharding the database mitigates the issue.  For example, an on-memory tree database containing 100 million records takes 24 seconds for the Synchronize method.  You can divide it into 100 shards.  Then, one shard takes only 0.24 seconds, which is not a problem in many cases.</p>

<p>The number of shards can be as large as you like.  The more the shards are, the better the concurrency performance is.  The downside of too many shard is that the iterator and the SearchModal method become slower.</p>

<h2 id="replication">Asynchronous Replication</h2>

<h2 id="replication_overview">Overview</h2>

<p>High availability is a concept to continue the service without any downtime even if some troubles including hardware failures happen.  Data replication is to store the same data on multiple machines, which is a common way to achieve high availability.  Tkrzw-RPC supports asynchronous replication, where data replication is done asynchrnounsly without waiting for the update data to reach a replica server.  It means that updates are lost if the server dies before the replica server replicates the updates.  Meanwhile, performance of asynchronous replication is much better than synchronous replication because the latency of each update query doesn't include the latency of the response of the replica server.</p>

<p>We call the server to which update queries are issued, as "master".  We call another server which monitors the updates on the master and replicate them, as "slave".  The master has to store update logs locally, which is realized by the message queue feature of the core library of Tkrzw.  The slave calls the "Replicate" RPC call to the master to fetch the update logs since a timestamp.  The slave applies the fetched updates on its own databases so that the databases on the master and the databases on the slave are synchronized.  The slave manaages the last timestamp of the fetched updates and use it to resume replication effectively.</p>

<div id="networdstructure" class="illustration"><img src="replication-simple.svg"/></div>

<p>As the databases on the master and the slave have the same content with only a slight delay, clients can retrieve data from either of them.  You can set up two or more slaves for load balancing of retrieval queries.  Updating queries must be called only to the master for consistency.</p>

<p>If the master dies, one of the slaves is promoted as the master.  The other slaves, if any, follows the new master.  If a slave dies, a new slave is added to keep high availability.  Usually, a slave is set up with a backup database and then the content is synchronized to the latest state by fetching updates since the timestamp of the backup database.  Usually, the slave is also configured to stores update logs so that it can be promoted as the master anytime when the original master dies.</p>

<h3 id="replication_client">Replication Client</h3>

<p>Let's set up a master server and monitor the updates with a client utility.  To set up the master, you have to specify the server ID and the prefix of the update log files.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "localhost:1978" \
  --async --threads 8 --log_level debug \
  --server_id 1 --ulog_prefix casket-1-ulog \
  "casket-1.tkh"
]]></code></pre>

<p>On another terminal, call update queries to the master.  The master database comes to have two records "one" and "two".  The two correspoinding update logs are stored in the update log file.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util set --address localhost:1978 one first
$ tkrzw_dbm_remote_util set --address localhost:1978 two second
]]></code></pre>

<p>Check the content of the update log file.  This command doesn't finish but waits for the next updates.  Keep it unfinished.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util replicate --address localhost:1978
1632472502596  1  0  SET  one  first
1632472506668  1  0  SET  two  second
]]></code></pre>

<p>On another terminal, send more update queries.  Two new update logs appear on the above terminal.  Then, finish the command on the above terminal by inputting Ctrl-C.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util set --address localhost:1978 three third
$ tkrzw_dbm_remote_util set --address localhost:1978 four fourth
]]></code></pre>

<p>You can retrieve update logs and apply them on local databases.  You specify the paths of the database files where update logs are applied.  If the file doesn't exist, a new database is created.  Also, you create the timestamp file by "--ts_file" option to store the last timestamp.  Also, you specify "--wait 0" and "--items 0", not to wait for the future updates.  After that, check the content of the updated database.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util replicate --address localhost:1978 \
  --ts_file casket-local.ts --wait 0 --items 0 casket-local.tkh
Opening DBM: casket-local.tkh
Using the minimum timestamp: 0
Connecting to the server: localhost:1978
Doing replication: localhost:1978
Done: timestamp=1632474357697

$ tkrzw_dbm_util list casket-local.tkh
three  third
two    second
four   fourth
one    first
]]></code></pre>

<p>In this way, you can make backup databases.  If the server manages multiple databases, you should specify the same number of databases.  You can update the backup databases by the same command.  The timestamp stored in the timestamp file is used to get update logs since the timestamp.</p>

<h3 id="replication_slave">Master-slave Topology</h3>

<p>The simplest topology of data replication is composed of one master and one slave.  Let's reuse the master server and the backup file for this excecise.  To set up a slave server, copy the backup database files and the timestamp file.  Then, run the server command specifying the address of the master server.  As we do this exercise on a single machine and the master uses the port 1978, we use the port 1979 for the slave server.  The slave also have a server ID which must be unique within your service architecture.  Setting of update logs should also be done because the slave can be treated as the master in the future.</p>

<pre><code class="language-shell-session"><![CDATA[$ cp casket-local.tkh casket-2.tkh
$ cp casket-local.ts casket-2.ts
$ tkrzw_server --address "localhost:1979" \
  --async --threads 8 --log_level debug \
  --server_id 2 --ulog_prefix casket-2-ulog \
  --repl_master "localhost:1978" --repl_ts_file casket-2.ts --repl_ts_skew -10000 \
  "casket-2.tkh"
]]></code></pre>

<p>The update logs between the current time and the timestamp stored in the timestamp file are retrieved and applied to the database automatically.  And, updates from now on are also synchronized on the spot.  To confirm it, put some records onto the master server and the list up the content of the slave database.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util set --address localhost:1978 five fifth
$ tkrzw_dbm_remote_util set --address localhost:1978 six sixth

$ tkrzw_dbm_remote_util list --address localhost:1979
five   fifth
three  third
two    second
four   fourth
one    first
six    sixth
]]></code></pre>

<p>Let's assume that the master dies and we promote the slave as the new master.  Stop the master and then add a new slabe.  This time, we don't specify the address of the new master but set it later.</p>

<pre><code class="language-shell-session"><![CDATA[$ cp casket-local.tkh casket-3.tkh
$ cp casket-local.ts casket-3.ts
$ tkrzw_server --address "localhost:1980" \
  --async --threads 8 --log_level debug \
  --server_id 3 --ulog_prefix casket-3-ulog \
  --repl_ts_file casket-3.ts \
  "casket-3.tkh"
]]></code></pre>

<p>At this point, replication is not started.  Thus, the records "five" and "six" doesn't exist.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util list --address localhost:1980
three  third
two    second
four   fourth
one    first
]]></code></pre>

<p>Let's start the replication by setting the master address to the slave server dynamically.  In this case, "localhost:1980" is the new slave and "localhost:1979" is the new master.  "--ts_skew -10000" means that replication starts from a point 10 seconds before the timestamp of the timestamp file.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util changemaster --address localhost:1980 \
  --ts_skew -10000 localhost:1979
]]></code></pre>

<p>Confirm that the content has been synchronized automatically.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util list --address localhost:1980
five   fifth
three  third
two    second
four   fourth
one    first
six    sixth
]]></code></pre>

<p>While updating queries must be done on the master, retrieval (non-updating) queries can be done on either the master or the slave.  Moreover, if retrieval queries are much more than updating queries, using multiple slave servers and doing load balancing is a good way to improve the throughput.</p>

<p>The timestamp of replication must always be given by the master.  The timestamp means a breakpoint from which the replication resumes on the master side.  The content of the timestamp file is the last timestamp given by the master, which is independent of the local clock.  Thus, even if the clock of the slave is skewed, replication works properly.  However, if the master dies and a slave becomes the new master, the timestamp is evaluated on the timeline of the new master machine, which is diffeerent from the old master.  Therefore, you should set "--repl_ts_skew" option of tkrzwr_server or "--ts_skew" option of tkrzw_dbm_remote_util with a netagive value to absorb a possible time leap.  Note that update logs are idempotent so duplicated application is acceptable.</p>

<h3 id="replication_slave">Dual Masters Topology</h3>

<p>Whereas the master-slave topology the basics of high availability, it still has downtime against update operations.  Between the time when the master dies and the time when the new master is set up and announced to all clients, updating operations cannot be done.  One workaround is to treat a pre-determined "prime" slave as the acting master.  If clients cannot access the master, they can call updating operations to the acting master.  However, it causes a potential problem of inconsistency.  For some reasons, even if the master is alive, some clients can be unable to access the master and update the acting master.  Then, if the acting master doesn't become the actual master, updates to it are lost.</p>

<p>Dual masters topology can solve this issue.  If the master replicates the prime slave, accidental updates to the prime slave are fed back to the master.  In the context of the dual master topology, the actual master is called "active master" and the prime slave is called "standby master".  To minimize possible inconsistency, clients should usually updates the active master.  Only if they cannot reach the active master, they are allowed to update the standby master.  The point is, each client can determine fallback measures by itself.  It avoids downtime completely at the risk of potential inconsistency which happens when the same record is updated on the active master and the standby master simultaneously.</p>

<p>Let's set up dual masters.  The server #1 at the port 1978 is the active master and the server #2 at the port 1979 is the standby master.  They replicates each other.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "localhost:1978" \
  --async --threads 8 --log_level debug \
  --server_id 1 --ulog_prefix casket-1-ulog \
  --repl_master "localhost:1979" --repl_ts_file casket-1.ts --repl_ts_skew -10000 \
  "casket-1.tkh"
]]></code></pre>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "localhost:1979" \
  --async --threads 8 --log_level debug \
  --server_id 2 --ulog_prefix casket-2-ulog \
  --repl_master "localhost:1978" --repl_ts_file casket-2.ts --repl_ts_skew -10000 \
  "casket-2.tkh"
]]></code></pre>

<p>Confirm that updates to one server are propagated to the other timely.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util set --address "localhost:1978" japan tokyo
$ tkrzw_dbm_remote_util get --address "localhost:1979" japan
tokyo
$ tkrzw_dbm_remote_util set --address "localhost:1979" korea seoul
$ tkrzw_dbm_remote_util get --address "localhost:1978" korea
seoul
]]></code></pre>

<p>Let's simulate that the active master dies by inputting Ctrl-C on the terminal.  The server #2 is concidered as the new active master.  Then, set up the server #3 at the port 1980 as the new standby master.  This time, we specify a non-existing database file so a new empty database is created.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_server --address "localhost:1980" \
  --async --threads 8 --log_level debug \
  --server_id 3 --ulog_prefix casket-3-ulog \
  --repl_master "localhost:1979" --repl_ts_file casket-3.ts --repl_ts_skew -10000 \
  "casket-3.tkh"
]]></code></pre>

<p>Confirm that the new database is synchronized automatically.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util list --address "localhost:1980"
japan   tokyo
korea   seoul
]]></code></pre>

<p>Modify the master address of the new active master to the new standby master.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_dbm_remote_util changemaster --address localhost:1979 \
  --ts_skew -10000 localhost:1980
]]></code></pre>

<p>You use multiple machines in the actual production service.  Moreover, you can shard one logical database into multiple shards each of which is composed of dual masters.  If the number of servers in operation is more than ten, you should automate the system configuration and server setups, combined with a monitoring system.</p>

<h3 id="replication_remove_old_ulog">Remove Old Update Log Files</h3>

<p>Update log files accumulate on each server.  After you make backup database files, you can remove update log files which are older than the backup files.  You can check the timestamp of each update log files by the following command.</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_ulog_util listfiles casket-ulog
./casket-ulog.0000000000    0    1632561080615    5.8 days    1073741824
./casket-ulog.0000000001    1    1632652635815    4.6 days    1073743335
./casket-ulog.0000000002    2    1632744191015    3.5 days    1073748723
./casket-ulog.0000000003    3    1632835746215    2.4 days    1073745432
./casket-ulog.0000000004    4    1632927301415    1.3 days    1073742564
]]></code></pre>

<p>You can remove update log files except for the latest one while the server is running.  If you want to remove files whose timestamp is older than 3 days ago, you run the following command.  Don't forget "-" of "-3D".</p>

<pre><code class="language-shell-session"><![CDATA[$ tkrzw_ulog_util removeoldfiles --timestamp "-3D" --exclude_latest casket-ulog
]]></code></pre>

<h2 id="faq">Frequently Asked Questions</h2>

<dl>
<dt>Q: Can I write a client library for a language?</dt>
<dd>A: Yes, please.  Fork the tkrzw_rpc.proto file to add options for the package name etc.</dd>
<dt>Q: Do you plan to support Windows?</dt>
<dd>A: Currently, no.  It's a matter of priority.</dd>
</dl>

<h2 id="license">License</h2>

<p>Tkrzw-RPC is written mainly by Mikio Hirabayashi, copyrighted by Google LLC, and distributed under the Apache license 2.0.  See the COPYING file in the package for detail.</p>

</article>
</body>
</html>
